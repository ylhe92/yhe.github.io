

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Rewards &mdash; highway-env  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/jupyter-sphinx.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Graphics" href="../graphics/index.html" />
    <link rel="prev" title="Behavior" href="../dynamics/vehicle/behavior.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> highway-env
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../user_guide.html">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../observations/index.html">Observations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../actions/index.html">Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dynamics/index.html">Dynamics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Rewards</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#most-environments">Most environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="#goal-environments">Goal environments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../graphics/index.html">Graphics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../make_your_own.html">Make your own environment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography/index.html">Bibliography</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">highway-env</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../user_guide.html">User Guide</a> &raquo;</li>
        
      <li>Rewards</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/rewards/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="rewards">
<span id="id1"></span><h1>Rewards<a class="headerlink" href="#rewards" title="Permalink to this headline">¶</a></h1>
<p>The reward function is defined in the <a class="reference internal" href="../make_your_own.html#highway_env.envs.common.abstract.AbstractEnv._reward" title="highway_env.envs.common.abstract.AbstractEnv._reward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_reward()</span></code></a> method, overloaded in every environment.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The choice of an appropriate reward function that yields realistic optimal driving behaviour is a challenging problem, that we do not address in this project.
In particular, we do not wish to specify every single aspect of the expected driving behaviour inside the reward function, such as keeping a safe distance to the front vehicle.
Instead, we would rather only specify a reward function as simple and straightforward as possible in order to see adequate behaviour emerge from learning.
In this perspective, keeping a safe distance is optimal not for being directly rewarded but for robustness against the uncertain behaviour of the leading vehicle, which could brake at any time.</p>
</div>
<div class="section" id="most-environments">
<h2>Most environments<a class="headerlink" href="#most-environments" title="Permalink to this headline">¶</a></h2>
<p>We generally focus on two features: a vehicle should</p>
<ul class="simple">
<li><p>progress quickly on the road;</p></li>
<li><p>avoid collisions.</p></li>
</ul>
<p>Thus, the reward function is often composed of a velocity term and a collision term:</p>
<div class="math notranslate nohighlight">
\[R(s,a) = a\frac{v - v_\min}{v_\max - v_\min} - b\,\text{collision}\]</div>
<p>where <span class="math notranslate nohighlight">\(v,\,v_\min,\,v_\max\)</span> are the current, minimum and maximum speed of the ego-vehicle respectively, and <span class="math notranslate nohighlight">\(a,\,b\)</span> are two coefficients.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since the rewards must be bounded, and the optimal policy is invariant by scaling and shifting rewards, we choose to normalize them in the <span class="math notranslate nohighlight">\([0, 1]\)</span> range, by convention.
Normalizing rewards has also been observed to be practically beneficial in deep reinforcement learning <a class="bibtex reference internal" href="../bibliography/index.html#mnih2015" id="id2">[MKS+15]</a>.
Note that we forbid negative rewards, since they may encourage the agent to prefer terminating an episode early (by causing a collision) rather than risking suffering a negative return if no satisfying trajectory can be found.</p>
</div>
<p>In some environments, the weight of the collision penalty can be configures through the <cite>collision_penalty</cite> parameter.</p>
</div>
<div class="section" id="goal-environments">
<h2>Goal environments<a class="headerlink" href="#goal-environments" title="Permalink to this headline">¶</a></h2>
<p>In the <a class="reference internal" href="../environments/parking.html#environments-parking"><span class="std std-ref">Parking</span></a> environment, however, the reward function must also specify the desired goal destination.
Thus, the velocity term is replaced by a weighted p-norm between the agent state and the goal state.</p>
<div class="math notranslate nohighlight">
\[R(s,a) = -\| s - s_g \|_{W,p}^p - b\,\text{collision}\]</div>
<p>where <span class="math notranslate nohighlight">\(s = [x, y, v_x, v_y, \cos\psi, \sin\psi]\)</span>, <span class="math notranslate nohighlight">\(s_g = [x_g, y_g, 0, 0, \cos\psi_g, \sin\psi_g]\)</span>, and
<span class="math notranslate nohighlight">\(\|x\|_{W,p} = (\sum_i |W_i x_i|^p)^{1/p}\)</span>. We use a p-norm rather than an Euclidean norm in order to have a narrower spike of rewards at the goal.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../graphics/index.html" class="btn btn-neutral float-right" title="Graphics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../dynamics/vehicle/behavior.html" class="btn btn-neutral float-left" title="Behavior" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018, Edouard Leurent

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>